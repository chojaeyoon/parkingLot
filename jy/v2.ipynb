{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "15b5b01698dca01f54617db7615e6c29839ce6e011c09452d03bb6af57b07af6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "\n",
    "from scipy import stats\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_row', 500)\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r'C:\\Users\\JY\\JYC\\Projects\\parkingLot\\data'\n",
    "\n",
    "rawtrain = pd.read_csv(PATH + '\\\\train.csv')\n",
    "rawtest = pd.read_csv(PATH + '\\\\test.csv')\n",
    "age_gender = pd.read_csv(PATH + '\\\\age_gender_info.csv', index_col=0)\n",
    "sample_submission = pd.read_csv(PATH + '\\\\sample_submission.csv')\n",
    "car_count = pd.read_csv(PATH + '\\\\car_count.csv', index_col = 0)"
   ]
  },
  {
   "source": [
    "###\n",
    "### 지역정보 join (운전가능연령 : 20~70대) : 여자운전비율과 남자운전비율을 계산하여 삽입"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "female = []\n",
    "male = []\n",
    "for col in age_gender.columns:\n",
    "    female.append(col) if '여자' in col else male.append(col)\n",
    "\n",
    "female_ratio = pd.DataFrame(age_gender[female].iloc[:,2:8].sum(axis=1), columns=['여자운전비율'])\n",
    "male_ratio = pd.DataFrame(age_gender[male].iloc[:, 2:8].sum(axis=1), columns=['남자운전비율'])\n",
    "\n",
    "rawtrain = pd.merge(rawtrain, female_ratio, on ='지역')\n",
    "rawtrain = pd.merge(rawtrain, male_ratio, on = '지역')\n",
    "rawtest = pd.merge(rawtest, female_ratio, on='지역')\n",
    "rawtest = pd.merge(rawtest, male_ratio, on= '지역')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "# rawtrain[rawtrain['임대보증금'] == '-']\n",
    "_t1 = rawtrain.groupby('단지코드').sum()['전용면적별세대수']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exception():\n",
    "    # 1. 전용면적별 세대수 합계 join\n",
    "    _t1 = rawtrain.groupby('단지코드').sum()['전용면적별세대수'] ### 이건 무슨 과정인가요?\n",
    "    _t2 = pd.merge(rawtrain, _t1, on = '단지코드')\n",
    "    _t2['전용면적별세대수'] = _t2['전용면적별세대수_x']\n",
    "    _t2['총세대수'] = _t2['전용면적별세대수_y'] \n",
    "    _final1 = _t2.drop(['전용면적별세대수_x', '전용면적별세대수_y'], axis = 'columns')\n",
    "\n",
    "    # 2. 제외할 코드들 제외\n",
    "    train = _final1[~_final1['단지코드'].isin(['C2085', 'C1397', 'C2431', 'C1649', 'C1036', 'C1095', \n",
    "                                             'C2051', 'C1218', 'C1894', 'C2483', 'C1502', 'C1988'])]\n",
    "    test = rawtest[~rawtest['단지코드'].isin(['C2675', 'C2335', 'C1327'])] \n",
    "\n",
    "    return train, test                                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = exception()"
   ]
  },
  {
   "source": [
    "###\n",
    "### 결측치 처리"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nanprocess_v1(usetrain):\n",
    "\n",
    "    \"\"\"\n",
    "        도보 10분거리내 지하철역 수: \"지역별로\" 결측치 제외 평균 0.5 미만이면 0, 이상이면 1 부여\n",
    "        cf. 대전과 충청남도에만 결측치 있음    \n",
    "        \n",
    "    \"\"\"\n",
    "    cities = list(set(usetrain['지역']))\n",
    "    aparts = list(set(usetrain['단지코드']))\n",
    "    _pre1 = usetrain.copy()\n",
    "    \n",
    "    _col = '도보 10분거리 내 지하철역 수(환승노선 수 반영)'\n",
    "    for city in tqdm(cities):\n",
    "        _aparts_in_city = usetrain[usetrain['지역'] == city]\n",
    "        _codes_in_city = list(set(_aparts_in_city['단지코드']))\n",
    "        \n",
    "        _mean = np.nanmean(_aparts_in_city[_col])\n",
    "        for code in _codes_in_city:\n",
    "            _idx = _pre1[_pre1['단지코드']==code].index\n",
    "            if usetrain[usetrain['단지코드'].isin(_codes_in_city)][_col].isnull().sum() > 0:\n",
    "                if _mean >= 0.5:\n",
    "                    _pre1.loc[_idx, _col] = 1\n",
    "                else:\n",
    "                    _pre1.loc[_idx, _col] = 0\n",
    "                    \n",
    "    \"\"\"\n",
    "        임대보증금 및 임대료: 결측치 제외하고, 단지별로, 전용면적과 선형회귀분석 진행하여 결측치 처리\n",
    "        cf. 임대보증금, 임대료에 '-' 값 있음: 결측치로 처리 \n",
    "        cf. C2152 아파트의 경우 임대보증금/임대료 데이터가 아예 결측 -> 강원도평균으로 처리\n",
    "        \n",
    "    \"\"\"        \n",
    "    # 임대가치 지표 신규 설정\n",
    "    _pre2 = _pre1.copy()\n",
    "    _col = ['임대보증금', '임대료']\n",
    "\n",
    "    for col in _col:\n",
    "        _pre2 = _pre2.drop(_pre2[_pre2[col] == '-'].index)\n",
    "        _pre2[col] = _pre2[col].astype(float)\n",
    "    _pre2['임대가치'] = _pre2['임대보증금'] * _pre2['임대료']\n",
    "    \n",
    "    return _pre1, _pre2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 16/16 [00:00<00:00, 19.95it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 53.00it/s]\n"
     ]
    }
   ],
   "source": [
    "_, prep_train = nanprocess_v1(train)\n",
    "_forC2152, prep_test = nanprocess_v1(test)\n",
    "\n",
    "# 강원도 임대가치 평균으로 C2152 결측치 처리\n",
    "_forC2152['임대가치'] = np.mean(prep_test[prep_test['지역']=='강원도']['임대가치'])\n",
    "prep_test = pd.concat([prep_test, _forC2152[_forC2152['단지코드'] == 'C2152']])\n",
    "\n",
    "# 테스트 결측데이터 처리\n",
    "prep_test.loc[400, '자격유형'] = 'A'\n",
    "prep_test.loc[599, '자격유형'] = 'C'\n",
    "\n",
    "prep = pd.concat([prep_train, prep_test])"
   ]
  },
  {
   "source": [
    "###\n",
    "### string 데이터 처리 / 상가 데이터 처리 (one-hot enc)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지역\n",
    "local_map = {}\n",
    "for i, loc in enumerate(prep['지역'].unique()):\n",
    "    _arr = [0] * len(prep['지역'].unique())\n",
    "    _arr[i] = 1\n",
    "    local_map[loc] = _arr\n",
    "    \n",
    "# 공급유형\n",
    "supply_map = {}\n",
    "for i, loc in enumerate(prep['공급유형'].unique()):\n",
    "    _arr = [0] * len(prep['공급유형'].unique())\n",
    "    _arr[i] = 1\n",
    "    supply_map[loc] = _arr\n",
    "    \n",
    "# 자격유형\n",
    "qual_map = {}\n",
    "for i, loc in enumerate(prep['자격유형'].unique()):\n",
    "    _arr = [0] * len(prep['자격유형'].unique())\n",
    "    _arr[i] = 1\n",
    "    qual_map[loc] = _arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 410/410 [00:04<00:00, 101.66it/s]\n",
      "100%|██████████| 147/147 [00:01<00:00, 106.60it/s]\n"
     ]
    }
   ],
   "source": [
    "def preprocess_v1(prep, type='train'):\n",
    "    aparts = list(set(prep['단지코드']))\n",
    "    merge_set = []\n",
    "    for code in tqdm(aparts):\n",
    "        final_vector = {}\n",
    "\n",
    "        usedat = prep[prep['단지코드'] == code]\n",
    "        onlyapart = usedat[usedat['임대건물구분'] == '아파트']\n",
    "        \n",
    "        if '상가' in set(usedat['임대건물구분']):\n",
    "            sanga = 1\n",
    "            sangadat = usedat[usedat['임대건물구분'] == '상가']\n",
    "            apartdat = usedat[usedat['임대건물구분'] == '아파트']\n",
    "            sanga_area = sum(sangadat['전용면적'] * sangadat['전용면적별세대수'])\n",
    "            apart_area = sum(apartdat['전용면적'] * apartdat['전용면적별세대수'])\n",
    "        else:\n",
    "            sanga = 0\n",
    "            sanga_area = 0.0\n",
    "            apart_area = sum(usedat['전용면적'] * usedat['전용면적별세대수'])\n",
    "        \n",
    "        final_vector['단지코드'] = [usedat['단지코드'].iloc[0]]\n",
    "        final_vector['총세대수'] = [usedat['총세대수'].iloc[0]]\n",
    "        final_vector['상가'] = [sanga]\n",
    "        final_vector['아파트면적'] = [apart_area]\n",
    "        final_vector['상가면적'] = [sanga_area]\n",
    "        \n",
    "        _onehot = sum([np.array(local_map[key]) for key in usedat['지역'].unique()])    # 지역정보\n",
    "        for tp in zip(list(local_map.keys()), list(_onehot)):\n",
    "            final_vector[tp[0]] = tp[1]\n",
    "            \n",
    "        _onehot = sum([np.array(supply_map[key]) * usedat.iloc[idx]['전용면적별세대수'] for idx, key in enumerate(usedat['공급유형'])])    # 공급유형\n",
    "        for tp in zip(supply_map.keys(), _onehot):\n",
    "            final_vector[tp[0]] = tp[1]\n",
    "            \n",
    "        _onehot = sum([np.array(qual_map[key]) * usedat.iloc[idx]['전용면적별세대수'] for idx, key in enumerate(usedat['자격유형'])])    # 자격유형\n",
    "        for tp in zip(qual_map.keys(), _onehot):\n",
    "            final_vector[tp[0]] = tp[1]     \n",
    "\n",
    "        final_vector['공가수'] = [usedat['공가수'].iloc[0]]            \n",
    "        final_vector['임대가치'] = [usedat['임대가치'].iloc[0]]\n",
    "        final_vector['지하철'] = [usedat['도보 10분거리 내 지하철역 수(환승노선 수 반영)'].iloc[0]]\n",
    "        final_vector['버스'] = [usedat['도보 10분거리 내 버스정류장 수'].iloc[0]]\n",
    "        final_vector['주차면수'] = [usedat['단지내주차면수'].iloc[0]]\n",
    "        if type == 'train':\n",
    "            final_vector['등록차량수'] = [usedat['등록차량수'].iloc[0]]\n",
    "        \n",
    "        del final_vector['공공분양']\n",
    "        \n",
    "        merge_set.append(pd.DataFrame(final_vector))\n",
    "    \n",
    "    return pd.concat(merge_set)\n",
    "\n",
    "finaltrain = preprocess_v1(prep_train).dropna()\n",
    "finaltest = preprocess_v1(prep_test, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    단지코드  총세대수  상가     아파트면적     상가면적  경상남도  대전광역시  경기도  전라북도  강원도  광주광역시  \\\n",
       "0  C1268  1035   0  46633.62     0.00     0      0    1     0    0      0   \n",
       "0  C2536    72   0   2722.32     0.00     0      0    0     1    0      0   \n",
       "0  C1866   338   0  13544.10     0.00     1      0    0     0    0      0   \n",
       "0  C2289  1527   1  42397.74  1427.03     0      0    0     0    0      0   \n",
       "0  C2437    90   0   2234.70     0.00     0      0    0     0    0      0   \n",
       "\n",
       "   충청남도  부산광역시  제주특별자치도  울산광역시  충청북도  전라남도  경상북도  대구광역시  서울특별시  세종특별자치시  국민임대  \\\n",
       "0     0      0        0      0     0     0     0      0      0        0  1035   \n",
       "0     0      0        0      0     0     0     0      0      0        0    72   \n",
       "0     0      0        0      0     0     0     0      0      0        0   338   \n",
       "0     0      1        0      0     0     0     0      0      0        0     0   \n",
       "0     0      0        0      0     1     0     0      0      0        0     0   \n",
       "\n",
       "   영구임대  임대상가  공공임대(50년)  공공임대(10년)  행복주택  공공임대(분납)  공공임대(5년)     A     C   D  \\\n",
       "0     0     0          0          0     0         0         0  1035     0   0   \n",
       "0     0     0          0          0     0         0         0    72     0   0   \n",
       "0     0     0          0          0     0         0         0   338     0   0   \n",
       "0  1507    20          0          0     0         0         0     0  1507  20   \n",
       "0    90     0          0          0     0         0         0     0    90   0   \n",
       "\n",
       "   E  H  I  L  K  J  B  G  N  M  O  F  공가수          임대가치  지하철  버스  주차면수  등록차량수  \n",
       "0  0  0  0  0  0  0  0  0  0  0  0  0   21  2.163645e+12  0.0  16   911    934  \n",
       "0  0  0  0  0  0  0  0  0  0  0  0  0    7  4.573296e+11  0.0   1    54     47  \n",
       "0  0  0  0  0  0  0  0  0  0  0  0  0    1  6.785381e+11  0.0   3   235    135  \n",
       "0  0  0  0  0  0  0  0  0  0  0  0  0    2  4.628443e+11  0.0   3   240    364  \n",
       "0  0  0  0  0  0  0  0  0  0  0  0  0   12  1.112505e+12  0.0   1    30     16  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>단지코드</th>\n      <th>총세대수</th>\n      <th>상가</th>\n      <th>아파트면적</th>\n      <th>상가면적</th>\n      <th>경상남도</th>\n      <th>대전광역시</th>\n      <th>경기도</th>\n      <th>전라북도</th>\n      <th>강원도</th>\n      <th>광주광역시</th>\n      <th>충청남도</th>\n      <th>부산광역시</th>\n      <th>제주특별자치도</th>\n      <th>울산광역시</th>\n      <th>충청북도</th>\n      <th>전라남도</th>\n      <th>경상북도</th>\n      <th>대구광역시</th>\n      <th>서울특별시</th>\n      <th>세종특별자치시</th>\n      <th>국민임대</th>\n      <th>영구임대</th>\n      <th>임대상가</th>\n      <th>공공임대(50년)</th>\n      <th>공공임대(10년)</th>\n      <th>행복주택</th>\n      <th>공공임대(분납)</th>\n      <th>공공임대(5년)</th>\n      <th>A</th>\n      <th>C</th>\n      <th>D</th>\n      <th>E</th>\n      <th>H</th>\n      <th>I</th>\n      <th>L</th>\n      <th>K</th>\n      <th>J</th>\n      <th>B</th>\n      <th>G</th>\n      <th>N</th>\n      <th>M</th>\n      <th>O</th>\n      <th>F</th>\n      <th>공가수</th>\n      <th>임대가치</th>\n      <th>지하철</th>\n      <th>버스</th>\n      <th>주차면수</th>\n      <th>등록차량수</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>C1268</td>\n      <td>1035</td>\n      <td>0</td>\n      <td>46633.62</td>\n      <td>0.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1035</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1035</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>21</td>\n      <td>2.163645e+12</td>\n      <td>0.0</td>\n      <td>16</td>\n      <td>911</td>\n      <td>934</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>C2536</td>\n      <td>72</td>\n      <td>0</td>\n      <td>2722.32</td>\n      <td>0.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>72</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>72</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7</td>\n      <td>4.573296e+11</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>54</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>C1866</td>\n      <td>338</td>\n      <td>0</td>\n      <td>13544.10</td>\n      <td>0.00</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>338</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>338</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>6.785381e+11</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>235</td>\n      <td>135</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>C2289</td>\n      <td>1527</td>\n      <td>1</td>\n      <td>42397.74</td>\n      <td>1427.03</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1507</td>\n      <td>20</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1507</td>\n      <td>20</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n      <td>4.628443e+11</td>\n      <td>0.0</td>\n      <td>3</td>\n      <td>240</td>\n      <td>364</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>C2437</td>\n      <td>90</td>\n      <td>0</td>\n      <td>2234.70</td>\n      <td>0.00</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>90</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>90</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12</td>\n      <td>1.112505e+12</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>30</td>\n      <td>16</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "finaltrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(357, 50)"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "finaltrain[finaltrain['임대가치']<5e12].shape"
   ]
  },
  {
   "source": [
    "###\n",
    "### Normalization"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = {}\n",
    "stds = {}\n",
    "for col in finaltrain.columns.difference(['단지코드']):\n",
    "    means[col] = np.mean(finaltrain[col])\n",
    "    stds[col] = np.std(finaltrain[col])\n",
    "    finaltrain[col] = (finaltrain[col] - means[col]) / stds[col]\n",
    "\n",
    "    \n",
    "for col in finaltest.columns.difference(['단지코드']):\n",
    "\n",
    "    finaltest[col] = (finaltest[col] - means[col]) / stds[col]"
   ]
  },
  {
   "source": [
    "###\n",
    "### 학습시작"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scikitplot'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-d5ee29e57d61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pycaret\\classification.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minternal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtabular\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minternal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDisplay\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_in_colab\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menable_colab\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pycaret\\internal\\tabular.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minternal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpatches\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myellowbrick\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minternal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_logger\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minternal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplotting\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshow_yellowbrick_plot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMatplotlibDefaultDPI\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minternal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDisplay\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minternal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pycaret\\internal\\plotting.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minternal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_logger\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mpycaret\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minternal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDisplay\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDisplay\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mscikitplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mskplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'scikitplot'"
     ]
    }
   ],
   "source": [
    "import pycaret\n",
    "from pycaret.classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation = {}\n",
    "except_val = []\n",
    "\n",
    "tmp_finaltrain = np.array(finaltrain[finaltrain.columns.difference(except_val)])\n",
    "np.random.seed(777)\n",
    "np.random.shuffle(np.array(tmp_finaltrain))\n",
    "thres = int(tmp_finaltrain.shape[0] / 5)\n",
    "\n",
    "x_train = pd.DataFrame(tmp_finaltrain[:-thres], columns=finaltrain.columns.difference(except_val))\n",
    "x_validation = pd.DataFrame(tmp_finaltrain[-thres:], columns=finaltrain.columns.difference(except_val))\n",
    "\n",
    "X = x_train[x_train.columns.difference(['등록차량수', '단지코드'])].astype(float)\n",
    "y = x_train[['등록차량수']].astype(float)\n",
    "\n",
    "def myLR():\n",
    "    model = LinearRegression()\n",
    "    fit = model.fit(X, y)\n",
    "    print(f'Linear Regression Score: {MAE(y, fit.predict(X))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myRegressor(regressor, param_grid):\n",
    "    start = time.time()\n",
    "    reg_grid = GridSearchCV(estimator=regressor,\n",
    "                            param_grid=param_grid,\n",
    "                            scoring='neg_mean_absolute_error',\n",
    "                            n_jobs=60,\n",
    "                            cv=5,\n",
    "                            refit=True,\n",
    "                            return_train_score=True)\n",
    "    reg_grid.fit(X, y)\n",
    "    result = pd.DataFrame(reg_grid.cv_results_)[\n",
    "        ['params', 'mean_test_score', 'rank_test_score']\n",
    "    ].sort_values(by='rank_test_score')\n",
    "    print(f'소요시간: {round((time.time() - start) / 60, 2)}분')\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalxgb(n_jobs, params):\n",
    "    start = time.time()\n",
    "    x_train, y_train = X.copy(), y.copy()\n",
    "    xgb_clf = xgb.XGBRegressor()\n",
    "    xgb_param_grid  = {\n",
    "        'learning_rate': params['learning_rate'],\n",
    "        'n_estimators': params['n_estimators'],\n",
    "        'max_depth': [5],\n",
    "        'min_child_weight': [1],\n",
    "        'gamma': [0],\n",
    "        'subsample': [0.8],\n",
    "        'colsample_bytree': [0.8],\n",
    "        'nthread': [-1],\n",
    "        'scale_pos_weight': [1],\n",
    "        'tree_method': ['gpu_hist'],\n",
    "        'gpu_id': params['gpu_id'],\n",
    "        'seed': [123]\n",
    "    }\n",
    "\n",
    "    def GridXGB(xgb_clf, xgb_param_grid):\n",
    "        hr_grid = GridSearchCV(estimator=xgb_clf,\n",
    "                           param_grid=xgb_param_grid,\n",
    "                           scoring='neg_mean_absolute_error',\n",
    "                           n_jobs=n_jobs,\n",
    "                           cv=5,\n",
    "                           refit=True,\n",
    "                           return_train_score=True)\n",
    "        hr_grid.fit(x_train, y_train)\n",
    "        return hr_grid\n",
    "\n",
    "    hr_grid = GridXGB(xgb_clf, xgb_param_grid)\n",
    "    hr_grid_df = pd.DataFrame(hr_grid.cv_results_).sort_values(by='rank_test_score')\n",
    "    print(f'Best MAE: {hr_grid_df.iloc[0][\"mean_test_score\"]}')\n",
    "\n",
    "    s1 = xgb_clf\n",
    "    s1.set_params(**hr_grid.best_params_)\n",
    "    print(f'Learning Rate, n_estimators FINISHED !! Time Spent: {round((time.time() - start) / 60, 2)} mins')\n",
    "    print(hr_grid.best_params_)\n",
    "\n",
    "    xgb_param_grid  = {\n",
    "        'max_depth': params['max_depth'],\n",
    "        'min_child_weight': [1, 2, 3, 4, 5]\n",
    "    }\n",
    "\n",
    "    hr_grid = GridXGB(s1, xgb_param_grid)\n",
    "    hr_grid_df = pd.DataFrame(hr_grid.cv_results_).sort_values(by='rank_test_score')\n",
    "    print(f'Best MAE: {hr_grid_df.iloc[0][\"mean_test_score\"]}')\n",
    "\n",
    "    s1 = xgb_clf\n",
    "    s1.set_params(**hr_grid.best_params_)\n",
    "    print(f'max_depth, min_child_weight FINISHED !! Time Spent: {round((time.time() - start) / 60, 2)} mins')\n",
    "    print(hr_grid.best_params_)\n",
    "\n",
    "    xgb_param_grid  = {\n",
    "        'gamma': params['gamma']\n",
    "    }\n",
    "\n",
    "    hr_grid = GridXGB(s1, xgb_param_grid)\n",
    "    hr_grid_df = pd.DataFrame(hr_grid.cv_results_).sort_values(by='rank_test_score')\n",
    "    print(f'Best MAE: {hr_grid_df.iloc[0][\"mean_test_score\"]}')\n",
    "\n",
    "    s1 = xgb_clf\n",
    "    s1.set_params(**hr_grid.best_params_)\n",
    "    print(f'gamma FINISHED !! Time Spent: {round((time.time() - start) / 60, 2)} mins')\n",
    "    print(hr_grid.best_params_)\n",
    "\n",
    "\n",
    "    xgb_param_grid  = {\n",
    "        'subsample': params['subsample'],\n",
    "        'colsample_bytree': params['colsample_bytree']\n",
    "    }\n",
    "\n",
    "    hr_grid = GridXGB(s1, xgb_param_grid)\n",
    "    hr_grid_df = pd.DataFrame(hr_grid.cv_results_).sort_values(by='rank_test_score')\n",
    "    print(f'Best MAE: {hr_grid_df.iloc[0][\"mean_test_score\"]}')\n",
    "\n",
    "    s1 = xgb_clf\n",
    "    s1.set_params(**hr_grid.best_params_)\n",
    "    print(f'subsample, colsample_bytree FINISHED !! Time Spent: {round((time.time() - start) / 60, 2)} mins')\n",
    "    print(hr_grid.best_params_)\n",
    "\n",
    "\n",
    "    xgb_param_grid  = {\n",
    "        'subsample': [i/100.0 for i in range(40,80)],\n",
    "    }\n",
    "\n",
    "    hr_grid = GridXGB(s1, xgb_param_grid)\n",
    "    hr_grid_df = pd.DataFrame(hr_grid.cv_results_).sort_values(by='rank_test_score')\n",
    "    print(f'Best MAE: {hr_grid_df.iloc[0][\"mean_test_score\"]}')\n",
    "\n",
    "    s1 = xgb_clf\n",
    "    s1.set_params(**hr_grid.best_params_)\n",
    "    print(f'subsample FINISHED !! Time Spent: {round((time.time() - start) / 60, 2)} mins')\n",
    "    print(hr_grid.best_params_)\n",
    "\n",
    "    xgb_param_grid = {\n",
    "     'reg_alpha': [1e-5, 1e-2, 0.1, 1, 100]\n",
    "    }\n",
    "\n",
    "    hr_grid = GridXGB(s1, xgb_param_grid)\n",
    "    hr_grid_df = pd.DataFrame(hr_grid.cv_results_).sort_values(by='rank_test_score')\n",
    "    print(f'Best MAE: {hr_grid_df.iloc[0][\"mean_test_score\"]}')\n",
    "\n",
    "    s1 = xgb_clf\n",
    "    s1.set_params(**hr_grid.best_params_)\n",
    "    print(f'Regularization FINISHED !! Time Spent: {round((time.time() - start) / 60, 2)} mins')\n",
    "    print(hr_grid.best_params_)\n",
    "\n",
    "    return hr_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {\n",
    "    'n_estimators': [10, 20, 30, 40, 50],\n",
    "    'criterion': ['mae'],\n",
    "    'max_depth': [20, 30, 40]\n",
    "}\n",
    "\n",
    "svr_params = {\n",
    "    'kernel': ['rbf'],\n",
    "    'C': [0.1, 1, 2, 3],\n",
    "    'epsilon': [0.01, 0.1, 0.5],\n",
    "}\n",
    "\n",
    "xgb_params = {\n",
    "    'max_depth': list(range(3, 11)),\n",
    "    'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "    'colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "    'gamma': [0, 3, 6, 9],\n",
    "    'tree_method':['gpu_hist'],\n",
    "    'gpu_id': [0],\n",
    "    'learning_rate': [0.2, 0.05, 0.005],\n",
    "    'n_estimators': [100, 200, 500]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\JY\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:880: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "소요시간: 2.56분\n",
      "소요시간: 0.02분\n",
      "C:\\Users\\JY\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "result_rf = myRegressor(RandomForestRegressor(), rf_params)\n",
    "result_svr = myRegressor(SVR(), svr_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "XGBoostError",
     "evalue": "[20:39:39] c:\\ci\\xgboost-split_1619728435298\\work\\src\\common\\common.h:156: XGBoost version not compiled with GPU support.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-47f1a730284d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresult_xgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinalxgb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-53-9ddf013577ce>\u001b[0m in \u001b[0;36mfinalxgb\u001b[1;34m(n_jobs, params)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhr_grid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mhr_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridXGB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgb_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxgb_param_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[0mhr_grid_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhr_grid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rank_test_score'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'Best MAE: {hr_grid_df.iloc[0][\"mean_test_score\"]}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-53-9ddf013577ce>\u001b[0m in \u001b[0;36mGridXGB\u001b[1;34m(xgb_clf, xgb_param_grid)\u001b[0m\n\u001b[0;32m     26\u001b[0m                            \u001b[0mrefit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m                            return_train_score=True)\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mhr_grid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhr_grid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    420\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m    595\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'eval_metric'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m         self._Booster = train(params, train_dmatrix,\n\u001b[0m\u001b[0;32m    598\u001b[0m                               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_num_boosting_rounds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m     \"\"\"\n\u001b[1;32m--> 227\u001b[1;33m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[0;32m    228\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m    100\u001b[0m         \u001b[1;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 102\u001b[1;33m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m             \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[0mversion\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1279\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1280\u001b[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1281\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1282\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \"\"\"\n\u001b[0;32m    188\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [20:39:39] c:\\ci\\xgboost-split_1619728435298\\work\\src\\common\\common.h:156: XGBoost version not compiled with GPU support."
     ]
    }
   ],
   "source": [
    "result_xgb = finalxgb(30, xgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor(**result_rf['params'].iloc[0])\n",
    "rf_model = rf_model.fit(X, y)\n",
    "\n",
    "svr_model = SVR(**result_svr['params'].iloc[0])\n",
    "svr_model = svr_model.fit(X, y)\n",
    "\n",
    "xgb_model = xgb.XGBRegressor(**result_xgb.best_params_)\n",
    "xgb_model = xgb_model.fit(X, y)"
   ]
  }
 ]
}